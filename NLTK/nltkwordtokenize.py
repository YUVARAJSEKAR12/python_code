# -*- coding: utf-8 -*-
"""NltkWordTokenize.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pDQW6wdi335YLBtqEO_WofoA3EWuWmbw
"""

pip install nltk


import nltk
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('averaged_perceptron_tagger')
nltk.download('maxent_ne_chunker')
nltk.download('words')



import nltk
from nltk.tokenize import word_tokenize

# Ensure NLTK's tokenizer is downloaded
nltk.download('punkt')

a = "Hi how are you"
tokens = word_tokenize(a)
print(tokens)